# BigData_overloaded
Allows to build a docker image overloaded with means library and tools

> Projet intentionnellement ‚Äúoverloaded‚Äù pour tester une stack data/ML compl√®te : 
Apache Spark 4, Python 3, scikit-learn, XGBoost, PostgreSQL 15, le tout orchestr√© avec Docker Compose.
L'ensembl permet de test de nombreuse configuration, librairie, ou mod√®le en jouant avec le script Python de base. 
Un dossier avec un script Faker Js √† adapt√© celons vos besoin pour alimenter de donn√©e fictive votre base de donn√©es dans votre container. 

## üß± Stack et services 

> Dossier FeedBDD  
> Ce dossier contient un script fakerJs pour nourrire votre base de donn√©e de donn√©es fictive. 

PostgreSQL 15 : base OLTP/feature store minimal.
Spark Master : planification/coordination du cluster.
Spark Worker : ex√©cute les t√¢ches (peut √™tre multipli√©).
Spark App : conteneur applicatif (scripts Python/ML, libs install√©es).

Ports expos√©s:
Postgres : 5432   
Spark Master (UI) : 8083 (redirig√© vers 8080 interne)  
Spark Master (cluster) : 7077  
Spark Worker (UI) : 8081  

Dans docker-compose.yml, le Master mappe 8083:8080 (UI) et 7077:7077 (cluster). Le Worker expose 8081:8081.

## ‚úÖ Pr√©requis

>Docker + Docker Compose (v2+)  
Node  
Ressources : pr√©voir ~4‚Äì8 Go de RAM libres pour Spark + Postgres.

## üìÅ Arborescence 
 ```bassh
.
‚îú‚îÄ data/ # jeux de donn√©es + scripts Python
‚îÇ ‚îî‚îÄ functionel_predict_incident_by_week.py
‚îú‚îÄ logs/
‚îÇ ‚îú‚îÄ sparkmaster/
‚îÇ ‚îú‚îÄ spark-worker-1/
‚îÇ ‚îî‚îÄ spark-app/
‚îú‚îÄ Dockerfile # image du service spark-app
‚îú‚îÄ requirements.txt # d√©pendances Python ML
‚îî‚îÄ docker-compose.yml # 
```

## üßæ Fichiers de config

#### 1) docker-compose.yaml => cr√©er vos services dans votre image docker.
#### 2) Dockerfile (pour spark-app) => construit le service qui lance le script.
#### 3) requirements.txt => list toute les d√©pendance utilie √† vortre projet. 

Modifier c'est fichier, pour ajouter ou retirer des librairie ou faire des modifications importante, puis re-builder votre image. 
 #### 4) Variables d‚Äôenvironnement (.env)

Vous pouvez d√©finir vos propres identifiants Postgres dans un fichier .env √† la racine du projet¬†:
 ```bassh
DB_USER=feed_incident
DB_PASSWORD=feed_incident
DB_NAME=feed_incident
```
Ces variables sont inject√©es automatiquement dans docker-compose.yml gr√¢ce √† la syntaxe ${VAR}¬†:

 ```bassh
services:
  db:
    image: postgres:15
    container_name: postgres_db
    restart: always
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
```

Vous pouvez ainsi changer rapidement vos identifiants en √©ditant uniquement le fichier .env, sans modifier docker-compose.yml.

### üìÇ Dossier data/ mapp√© dans le conteneur
Le dossier data/ √† la racine du projet est partag√© avec le r√©pertoire /opt/spark/data √† l‚Äôint√©rieur du conteneur spark-app (et aussi dans les services Spark Master et Worker).

Cela signifie que :

Si vous ajoutez un script Python dans ```./data``` sur votre machine h√¥te, il sera automatiquement visible dans le conteneur sous ```/opt/spark/data```.

Vous pouvez donc d√©velopper vos scripts localement et les ex√©cuter directement dans le conteneur sans rebuild.

### Exemple :
Cr√©ez un script localement :   
  ```data/mon_script.py```

Entrez dans le conteneur :  
```docker exec -it spark-app /bin/bash```

Ex√©cutez la commande suivante pour lancer votre script:  
```python3 /opt/spark/data/mon_script.py```

Ce m√©canisme est tr√®s pratique pour it√©rer rapidement sur vos jobs Spark ou vos mod√®les ML.

## üöÄ Build & d√©marrage

Construire l‚Äôimage applicative (spark-app) et d√©marrer l‚Äôensemble :
```bash 
docker compose up -d --build 
```
V√©rifier que tout est parti :
```bash 
docker compose ps
```
UIs :  
Spark Master UI : http://localhost:8083  
Spark Worker-1 UI : http://localhost:8081  
Postgres (CLI externe) : psql postgresql://feed_incident:feed_incident@localhost:5432/feed_incident  

## üß∞ Travailler dans le conteneur spark-app
#### 1) Ouvrir un shell interactif
```bash 
docker exec -it spark-app /bin/bash
```
 Cette commande vous permet d'entrer dans votre container depuis un terminale.
#### 2) Lancer un script Python ¬´ pur ¬ª (scikit-learn / XGBoost)
```bash 
python3 /opt/spark/data/functionel_predict_incident_by_week.py
```

## üõ†Ô∏è Probl√®mes courants & astuces

* Ports d√©j√† utilis√©s : changez 8083/8081/5432 dans docker-compose.yml.

* Le Worker ne rejoint pas le Master : v√©rifiez command du worker et que spark://spark-master:7077 est reachable (logs du Worker, pare-feu local).

* D√©pendances Python manquantes : rebuild avec --build apr√®s avoir modifi√© requirements.txt.

* Acc√®s DB depuis Spark : n‚Äôutilisez pas localhost mais postgres_db comme host.

* M√©moire insuffisante : r√©duisez la taille des jobs ou augmentez la RAM Docker. Vous pouvez aussi limiter les ressources des services via deploy.resources.
* V√©rifier les droits de lecture et d'√©criture de vos fichier. (Spark √† besoin d'√©crire dans les dossier de son container mais aussi sur les dossier mapper sur votre machine)